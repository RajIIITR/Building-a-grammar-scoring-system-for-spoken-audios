{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97919,"databundleVersionId":11694977,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:07:40.830832Z","iopub.execute_input":"2025-04-07T15:07:40.831128Z","iopub.status.idle":"2025-04-07T15:07:41.550140Z","shell.execute_reply.started":"2025-04-07T15:07:40.831106Z","shell.execute_reply":"2025-04-07T15:07:41.549473Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"**Doing translation of a Sample audio .wev file to text**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\nimport torch\nimport torchaudio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:07:41.551380Z","iopub.execute_input":"2025-04-07T15:07:41.551715Z","iopub.status.idle":"2025-04-07T15:08:02.943440Z","shell.execute_reply.started":"2025-04-07T15:07:41.551673Z","shell.execute_reply":"2025-04-07T15:08:02.942719Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntorch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:08:02.944932Z","iopub.execute_input":"2025-04-07T15:08:02.945510Z","iopub.status.idle":"2025-04-07T15:08:03.032468Z","shell.execute_reply.started":"2025-04-07T15:08:02.945487Z","shell.execute_reply":"2025-04-07T15:08:03.031484Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Loading basic things required for whisper translation <br>\nReference: \nHuggingFace:  https://huggingface.co/openai/whisper-large-v3-turbo\nMedium:  https://medium.com/@jatin.dhall7385/pythonic-wav-file-handling-a-guide-to-reading-wav-files-without-external-libraries-f5869b27b2e7","metadata":{}},{"cell_type":"code","source":"# Model \nmodel_id = \"openai/whisper-large-v3-turbo\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:08:03.033899Z","iopub.execute_input":"2025-04-07T15:08:03.034255Z","iopub.status.idle":"2025-04-07T15:08:03.051472Z","shell.execute_reply.started":"2025-04-07T15:08:03.034218Z","shell.execute_reply":"2025-04-07T15:08:03.050662Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load the model and processor\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True)\nmodel.to(device)\nprocessor = AutoProcessor.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:08:03.052449Z","iopub.execute_input":"2025-04-07T15:08:03.052693Z","iopub.status.idle":"2025-04-07T15:08:14.522556Z","shell.execute_reply.started":"2025-04-07T15:08:03.052668Z","shell.execute_reply":"2025-04-07T15:08:14.521654Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67056b9225dd4ff6ba365a42c5013225"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.62G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aceeec03239419984368fc131d822de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38dca512d2a340b0a2639ef2e3b3f3ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"327c08573dc142db88a98e8e7e4fbdd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f1577b644f4e348072c7e13c3eb37f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2c5a1cf5ec44c458eeb12b57d8f9aec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce3fcb8237684575bca334566b081a35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c5e0ec12cf849d48840140e347f4f02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57da34e993e34af79776fd5ff876b5e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c2a3eefed74073bb0fd643e893d9c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffcef6e9d89649da82827d34186250bd"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Initialize the pipeline\nasr_pipeline = pipeline(\n    \"automatic-speech-recognition\",\n    model=model,\n    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n    torch_dtype=torch_dtype,\n    device=device,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:08:14.523540Z","iopub.execute_input":"2025-04-07T15:08:14.523841Z","iopub.status.idle":"2025-04-07T15:08:14.529286Z","shell.execute_reply.started":"2025-04-07T15:08:14.523820Z","shell.execute_reply":"2025-04-07T15:08:14.528420Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Sample Audio file path (Example)\nfile_path = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1024.wav\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:08:14.530158Z","iopub.execute_input":"2025-04-07T15:08:14.530439Z","iopub.status.idle":"2025-04-07T15:08:16.856793Z","shell.execute_reply.started":"2025-04-07T15:08:14.530385Z","shell.execute_reply":"2025-04-07T15:08:16.855753Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load audio and preprocess\naudio, sr = librosa.load(file_path, sr=16000, mono=True)  # Ensure mono and 16kHz\ninputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\").to(device, torch_dtype)\n\n# Generate token ids and decode\nwith torch.no_grad():\n    generated_ids = model.generate(inputs[\"input_features\"])\n\n# Decode the predicted tokens into text\ntranscription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\nprint(\"Transcription:\", transcription)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:22:51.640608Z","iopub.execute_input":"2025-04-07T15:22:51.640886Z","iopub.status.idle":"2025-04-07T15:23:07.258428Z","shell.execute_reply.started":"2025-04-07T15:22:51.640866Z","shell.execute_reply":"2025-04-07T15:23:07.257648Z"}},"outputs":[{"name":"stderr","text":"Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"Transcription:  my favorite plate places is in on the place it is in Chitra district it is it is the it is a temple of see Lord Ventes or a swami it has seven hills to visit the temple it is a good place to\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"The whisper model can handle input audio in one shot is usually 30 seconds max per segment. (Approx)","metadata":{}},{"cell_type":"markdown","source":"So we will perform silding window technique so it captures first 30 sec then followed by remaining time so that in total it captures the entire 60 seconds audio and give us text translation","metadata":{}},{"cell_type":"code","source":"def transcribe_audio(file_path, segment_length=30):\n    # Load audio\n    waveform, sr = torchaudio.load(file_path)\n\n    # Convert to mono if stereo\n    if waveform.size(0) > 1:\n        waveform = waveform.mean(dim=0, keepdim=True)\n\n    # Resample to 16kHz if not already\n    if sr != 16000:\n        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n        waveform = resampler(waveform)\n\n    # Number of samples in each segment\n    segment_samples = segment_length * 16000  # 30 sec chunks\n\n    transcriptions = []\n\n    for start in range(0, waveform.size(1), segment_samples):\n        end = min(start + segment_samples, waveform.size(1))\n        segment = waveform[:, start:end].squeeze().numpy()\n\n        try:\n            result = asr_pipeline(segment)\n            transcriptions.append(result['text'])\n        except Exception as e:\n            print(f\"Error transcribing segment {start}-{end}: {e}\")\n            transcriptions.append(\"\")\n\n    return \" \".join(transcriptions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:23:07.259465Z","iopub.execute_input":"2025-04-07T15:23:07.259986Z","iopub.status.idle":"2025-04-07T15:23:07.265847Z","shell.execute_reply.started":"2025-04-07T15:23:07.259966Z","shell.execute_reply":"2025-04-07T15:23:07.264973Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Loading all library\n\nimport os\nimport pandas as pd\nimport torch\nimport numpy as np\nimport librosa\nimport time\nfrom transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:22:48.570150Z","iopub.execute_input":"2025-04-07T15:22:48.570599Z","iopub.status.idle":"2025-04-07T15:22:48.586709Z","shell.execute_reply.started":"2025-04-07T15:22:48.570561Z","shell.execute_reply":"2025-04-07T15:22:48.585693Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"text = transcribe_audio(file_path)\nprint(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:23:07.267520Z","iopub.execute_input":"2025-04-07T15:23:07.267748Z","iopub.status.idle":"2025-04-07T15:23:08.852470Z","shell.execute_reply.started":"2025-04-07T15:23:07.267728Z","shell.execute_reply":"2025-04-07T15:23:08.851491Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" my favorite plate places is in on the place it is in Chitra district it is it is the it is a temple of see Lord Ventes or a swami it has seven hills to visit the temple it is a good place to  receive the Thirumala for India here crowds of people to visit the Lord Venteshwaraswamy in Thirumala have a lot of a lot of places to visit the visit the tourists in in Thirumala laddu is very famous  you\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**Now we had done transcription with respect to few example.\nLets do transcription of entire audios_train to their respective translation in text format and map it to their respective audio file in train_csv**","metadata":{}},{"cell_type":"code","source":"def load_whisper_model():\n    \"\"\"\n    Initializing Whisper Model\n    \n    Returns:\n        pipeline: Hugging Face pipeline for automatic speech recognition\n\n    Reference:\n        HuggingFace \n    \"\"\"\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n    print(f\"Using device: {device}\")\n    \n    model_id = \"openai/whisper-large-v3-turbo\"\n    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n        model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n    )\n    model.to(device)\n    \n    processor = AutoProcessor.from_pretrained(model_id)\n    pipe = pipeline(\n        \"automatic-speech-recognition\",\n        model=model,\n        tokenizer=processor.tokenizer,\n        feature_extractor=processor.feature_extractor,\n        torch_dtype=torch_dtype,\n        device=device,\n    )\n    \n    return pipe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:23:08.854036Z","iopub.execute_input":"2025-04-07T15:23:08.854277Z","iopub.status.idle":"2025-04-07T15:23:08.859513Z","shell.execute_reply.started":"2025-04-07T15:23:08.854257Z","shell.execute_reply":"2025-04-07T15:23:08.858435Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def load_audio(file_path):\n    \"\"\"\n    Load an audio file and convert it to mono if stereo. (As there are some file which are not mono which gave me an error earlier that transcription column doesn't matches the train.csv size)\n    \n    Args:\n        file_path: Path to the audio file\n        \n    Returns:\n        audio_data: Audio data as numpy array\n        sample_rate: Sample rate of the audio\n     Sample rate refers to the number of audio samples taken per second when digitizing an audio signal. (kHz unit)\n    \"\"\"\n    audio, sample_rate = librosa.load(file_path, sr=16000, mono=False)\n    \n    # Check if audio is stereo (2D array) and convert to mono if needed\n    if len(audio.shape) > 1 and audio.shape[0] == 2:\n        print(f\"Converting stereo to mono for {os.path.basename(file_path)}\")\n        audio = np.mean(audio, axis=0)\n    \n    return audio, sample_rate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:23:08.860473Z","iopub.execute_input":"2025-04-07T15:23:08.860811Z","iopub.status.idle":"2025-04-07T15:23:08.880893Z","shell.execute_reply.started":"2025-04-07T15:23:08.860778Z","shell.execute_reply":"2025-04-07T15:23:08.879953Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def transcribe_long_audio(pipe, audio, sample_rate, window_size=30, overlap=1):\n    \"\"\"\n    Transcribe audio that may be longer than 30 seconds using a sliding window approach.\n    \n    Args:\n        pipe: Whisper pipeline for transcription (Obtain from load_whisper_model function)\n        audio: Audio data as numpy array  (Obtain from load_audio)\n        sample_rate: Sample rate of the audio  (Obtain from load_audio)\n        window_size: Size of the sliding window in seconds   (Since whisper model can translate 30 sec audio at a time we had used sliding window technique in our work)\n        overlap: Overlap between windows in seconds   (Overlapping the time frame between two windows)\n        \n    Returns:\n        full_transcription: Complete transcription of the audio\n    \"\"\"\n    # Calculate window and stride sizes in samples\n    window_samples = window_size * sample_rate\n    stride_samples = (window_size - overlap) * sample_rate\n    \n    # If audio is shorter than window_size, just transcribe it directly\n    if len(audio) <= window_samples:\n        result = pipe({\"sampling_rate\": sample_rate, \"raw\": audio})\n        return result[\"text\"].strip()\n    \n    # else For longer audio, use sliding window approach\n    transcriptions = []\n    \n    # Calculate number of windows (Though we know that in 2 window we will cover the task but made it more general)\n    num_windows = max(1, int(np.ceil((len(audio) - window_samples) / stride_samples)) + 1)\n    \n    for i in range(num_windows):\n        start_sample = int(i * stride_samples)\n        end_sample = min(len(audio), start_sample + window_samples)\n        \n        # Extract audio segment\n        audio_segment = audio[start_sample:end_sample]\n        \n        # Transcribe segment\n        result = pipe({\"sampling_rate\": sample_rate, \"raw\": audio_segment})\n        transcriptions.append(result[\"text\"].strip())\n    \n    # Merge all transcriptions\n    full_transcription = \" \".join(transcriptions)\n    return full_transcription","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:23:08.881690Z","iopub.execute_input":"2025-04-07T15:23:08.881907Z","iopub.status.idle":"2025-04-07T15:23:08.898477Z","shell.execute_reply.started":"2025-04-07T15:23:08.881889Z","shell.execute_reply":"2025-04-07T15:23:08.897566Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"**Now we will map all audio translates with their Audio file name in train_csv file & store it in new csv file name train_with_transcription.csv**","metadata":{}},{"cell_type":"code","source":"def transcribe_audio_files(audio_folder, csv_path):\n    \"\"\"\n    Transcribe all audio files listed in the CSV and add transcriptions as a new column.\n    \n    Args:\n        audio_folder: Path to folder containing audio files\n        csv_path: Path to CSV file with list of audio files\n        \n    Returns:\n        df: DataFrame with added transcription column\n    \"\"\"\n\n    # Load CSV file\n    df = pd.read_csv(csv_path)\n    print(f\"Loaded CSV with {len(df)} entries\")\n    \n    # Load Whisper model pipeline define earlier\n    pipe = load_whisper_model()\n    \n    # Create a new column for transcriptions\n    df['transcription'] = \"\"\n    \n    # For loop to iterate through each audio file and add transcription of it\n    print(\"Starting transcription process...\")\n    for i, row in df.iterrows():\n        audio_file = row['filename']  \n        full_path = os.path.join(audio_folder, audio_file)\n        \n        try:\n            # Print progress\n            print(f\"Processing file {i+1}/{len(df)}: {audio_file}\")\n            \n            # Load and convert audio file\n            audio, sample_rate = load_audio(full_path)\n            \n            # Transcribe audio\n            transcription = transcribe_long_audio(pipe, audio, sample_rate)\n            \n            # Add transcription to dataframe\n            df.at[i, 'transcription'] = transcription\n            \n            # Add a small delay to prevent overloading \n            if (i + 1) % 10 == 0:\n                print(f\"Processed {i+1} files. Taking a short break...\")\n                time.sleep(1)\n                \n        except Exception as e:\n            print(f\"Error processing {audio_file}: {str(e)}\")\n            df.at[i, 'transcription'] = \"ERROR: Could not transcribe\"\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:23:08.899247Z","iopub.execute_input":"2025-04-07T15:23:08.899520Z","iopub.status.idle":"2025-04-07T15:23:08.923170Z","shell.execute_reply.started":"2025-04-07T15:23:08.899492Z","shell.execute_reply":"2025-04-07T15:23:08.922267Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def main():\n    \"\"\"\n    Main function to run the transcription process.\n    \"\"\"\n    #  paths\n    audio_folder = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train\"\n    csv_path = \"/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\"\n    output_path = \"/kaggle/working/train_with_transcriptions.csv\"\n    \n    # Transcribe audio files\n    df = transcribe_audio_files(audio_folder, csv_path)\n    \n    # Save the updated dataframe\n    df.to_csv(output_path, index=False)\n    print(f\"Transcription complete! Saved to {output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:23:08.925666Z","iopub.execute_input":"2025-04-07T15:23:08.925923Z","iopub.status.idle":"2025-04-07T15:23:08.945967Z","shell.execute_reply.started":"2025-04-07T15:23:08.925899Z","shell.execute_reply":"2025-04-07T15:23:08.945161Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:23:08.947053Z","iopub.execute_input":"2025-04-07T15:23:08.947356Z","iopub.status.idle":"2025-04-07T15:37:12.684013Z","shell.execute_reply.started":"2025-04-07T15:23:08.947311Z","shell.execute_reply":"2025-04-07T15:37:12.683241Z"}},"outputs":[{"name":"stdout","text":"Loaded CSV with 444 entries\nUsing device: cuda:0\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\n/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting transcription process...\nProcessing file 1/444: audio_1261.wav\nProcessing file 2/444: audio_942.wav\nProcessing file 3/444: audio_1110.wav\nProcessing file 4/444: audio_1024.wav\n","output_type":"stream"},{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"Processing file 5/444: audio_538.wav\nProcessing file 6/444: audio_350.wav\nProcessing file 7/444: audio_64.wav\nProcessing file 8/444: audio_252.wav\nProcessing file 9/444: audio_1304.wav\nProcessing file 10/444: audio_1230.wav\nProcessed 10 files. Taking a short break...\nProcessing file 11/444: audio_133.wav\nProcessing file 12/444: audio_790.wav\nProcessing file 13/444: audio_947.wav\nProcessing file 14/444: audio_288.wav\nProcessing file 15/444: audio_1111.wav\nProcessing file 16/444: audio_771.wav\nProcessing file 17/444: audio_1184.wav\nProcessing file 18/444: audio_918.wav\nProcessing file 19/444: audio_1030.wav\nProcessing file 20/444: audio_1112.wav\nProcessed 20 files. Taking a short break...\nProcessing file 21/444: audio_873.wav\nProcessing file 22/444: audio_539.wav\nProcessing file 23/444: audio_899.wav\nProcessing file 24/444: audio_1277.wav\nProcessing file 25/444: audio_649.wav\nProcessing file 26/444: audio_701.wav\nProcessing file 27/444: audio_763.wav\nProcessing file 28/444: audio_952.wav\nProcessing file 29/444: audio_167.wav\nProcessing file 30/444: audio_708.wav\nProcessed 30 files. Taking a short break...\nProcessing file 31/444: audio_1245.wav\nProcessing file 32/444: audio_812.wav\nProcessing file 33/444: audio_76.wav\nProcessing file 34/444: audio_1296.wav\nProcessing file 35/444: audio_239.wav\nProcessing file 36/444: audio_668.wav\nProcessing file 37/444: audio_17.wav\nProcessing file 38/444: audio_289.wav\nProcessing file 39/444: audio_45.wav\nProcessing file 40/444: audio_657.wav\nProcessed 40 files. Taking a short break...\nProcessing file 41/444: audio_876.wav\nProcessing file 42/444: audio_1069.wav\nConverting stereo to mono for audio_1069.wav\nProcessing file 43/444: audio_1318.wav\nProcessing file 44/444: audio_832.wav\nProcessing file 45/444: audio_917.wav\nProcessing file 46/444: audio_802.wav\nProcessing file 47/444: audio_275.wav\nProcessing file 48/444: audio_940.wav\nProcessing file 49/444: audio_1120.wav\nProcessing file 50/444: audio_535.wav\nProcessed 50 files. Taking a short break...\nProcessing file 51/444: audio_244.wav\nProcessing file 52/444: audio_1134.wav\nProcessing file 53/444: audio_724.wav\nProcessing file 54/444: audio_965.wav\nProcessing file 55/444: audio_1031.wav\nProcessing file 56/444: audio_1326.wav\nProcessing file 57/444: audio_1325.wav\nProcessing file 58/444: audio_273.wav\nProcessing file 59/444: audio_1298.wav\nProcessing file 60/444: audio_868.wav\nProcessed 60 files. Taking a short break...\nProcessing file 61/444: audio_964.wav\nProcessing file 62/444: audio_85.wav\nProcessing file 63/444: audio_919.wav\nProcessing file 64/444: audio_303.wav\nProcessing file 65/444: audio_345.wav\nProcessing file 66/444: audio_930.wav\nProcessing file 67/444: audio_817.wav\nProcessing file 68/444: audio_1104.wav\nProcessing file 69/444: audio_836.wav\nProcessing file 70/444: audio_946.wav\nProcessed 70 files. Taking a short break...\nProcessing file 71/444: audio_1312.wav\nProcessing file 72/444: audio_324.wav\nProcessing file 73/444: audio_913.wav\nProcessing file 74/444: audio_399.wav\nProcessing file 75/444: audio_766.wav\nProcessing file 76/444: audio_748.wav\nProcessing file 77/444: audio_1114.wav\nProcessing file 78/444: audio_1251.wav\nProcessing file 79/444: audio_59.wav\nProcessing file 80/444: audio_889.wav\nProcessed 80 files. Taking a short break...\nProcessing file 81/444: audio_130.wav\nProcessing file 82/444: audio_297.wav\nProcessing file 83/444: audio_744.wav\nProcessing file 84/444: audio_779.wav\nProcessing file 85/444: audio_1210.wav\nProcessing file 86/444: audio_680.wav\nProcessing file 87/444: audio_944.wav\nProcessing file 88/444: audio_8.wav\nProcessing file 89/444: audio_1057.wav\nProcessing file 90/444: audio_722.wav\nProcessed 90 files. Taking a short break...\nProcessing file 91/444: audio_1036.wav\nProcessing file 92/444: audio_760.wav\nProcessing file 93/444: audio_675.wav\nProcessing file 94/444: audio_62.wav\nProcessing file 95/444: audio_865.wav\nProcessing file 96/444: audio_654.wav\nProcessing file 97/444: audio_743.wav\nProcessing file 98/444: audio_950.wav\nProcessing file 99/444: audio_77.wav\nProcessing file 100/444: audio_916.wav\nProcessed 100 files. Taking a short break...\nProcessing file 101/444: audio_1028.wav\nProcessing file 102/444: audio_727.wav\nProcessing file 103/444: audio_146.wav\nProcessing file 104/444: audio_642.wav\nProcessing file 105/444: audio_1313.wav\nProcessing file 106/444: audio_1208.wav\nProcessing file 107/444: audio_640.wav\nProcessing file 108/444: audio_778.wav\nProcessing file 109/444: audio_1025.wav\nProcessing file 110/444: audio_939.wav\nProcessed 110 files. Taking a short break...\nProcessing file 111/444: audio_1216.wav\nProcessing file 112/444: audio_934.wav\nProcessing file 113/444: audio_904.wav\nProcessing file 114/444: audio_1102.wav\nProcessing file 115/444: audio_1150.wav\nProcessing file 116/444: audio_765.wav\nProcessing file 117/444: audio_1117.wav\nProcessing file 118/444: audio_685.wav\nProcessing file 119/444: audio_1329.wav\nProcessing file 120/444: audio_236.wav\nProcessed 120 files. Taking a short break...\nProcessing file 121/444: audio_90.wav\nProcessing file 122/444: audio_903.wav\nProcessing file 123/444: audio_905.wav\nProcessing file 124/444: audio_736.wav\nProcessing file 125/444: audio_886.wav\nProcessing file 126/444: audio_773.wav\nProcessing file 127/444: audio_43.wav\nProcessing file 128/444: audio_853.wav\nProcessing file 129/444: audio_278.wav\nProcessing file 130/444: audio_948.wav\nProcessed 130 files. Taking a short break...\nProcessing file 131/444: audio_869.wav\nProcessing file 132/444: audio_1223.wav\nProcessing file 133/444: audio_1038.wav\nProcessing file 134/444: audio_686.wav\nProcessing file 135/444: audio_346.wav\nProcessing file 136/444: audio_988.wav\nProcessing file 137/444: audio_653.wav\nProcessing file 138/444: audio_809.wav\nProcessing file 139/444: audio_1043.wav\nProcessing file 140/444: audio_542.wav\nProcessed 140 files. Taking a short break...\nProcessing file 141/444: audio_1106.wav\nProcessing file 142/444: audio_643.wav\nProcessing file 143/444: audio_1333.wav\nProcessing file 144/444: audio_1239.wav\nProcessing file 145/444: audio_1264.wav\nProcessing file 146/444: audio_854.wav\nProcessing file 147/444: audio_681.wav\nProcessing file 148/444: audio_711.wav\nProcessing file 149/444: audio_5.wav\nProcessing file 150/444: audio_446.wav\nProcessed 150 files. Taking a short break...\nProcessing file 151/444: audio_827.wav\nProcessing file 152/444: audio_67.wav\nProcessing file 153/444: audio_776.wav\nProcessing file 154/444: audio_93.wav\nProcessing file 155/444: audio_677.wav\nProcessing file 156/444: audio_1226.wav\nProcessing file 157/444: audio_1136.wav\nProcessing file 158/444: audio_536.wav\nProcessing file 159/444: audio_1247.wav\nProcessing file 160/444: audio_61.wav\nProcessed 160 files. Taking a short break...\nProcessing file 161/444: audio_336.wav\nProcessing file 162/444: audio_661.wav\nProcessing file 163/444: audio_788.wav\nProcessing file 164/444: audio_1212.wav\nProcessing file 165/444: audio_813.wav\nProcessing file 166/444: audio_1118.wav\nProcessing file 167/444: audio_678.wav\nProcessing file 168/444: audio_427.wav\nProcessing file 169/444: audio_755.wav\nProcessing file 170/444: audio_110.wav\nProcessed 170 files. Taking a short break...\nProcessing file 171/444: audio_859.wav\nProcessing file 172/444: audio_957.wav\nProcessing file 173/444: audio_1252.wav\nProcessing file 174/444: audio_1126.wav\nProcessing file 175/444: audio_699.wav\nProcessing file 176/444: audio_1314.wav\nProcessing file 177/444: audio_794.wav\nProcessing file 178/444: audio_1129.wav\nProcessing file 179/444: audio_808.wav\nProcessing file 180/444: audio_875.wav\nProcessed 180 files. Taking a short break...\nProcessing file 181/444: audio_842.wav\nProcessing file 182/444: audio_1182.wav\nProcessing file 183/444: audio_848.wav\nProcessing file 184/444: audio_1040.wav\nProcessing file 185/444: audio_956.wav\nProcessing file 186/444: audio_902.wav\nProcessing file 187/444: audio_441.wav\nProcessing file 188/444: audio_237.wav\nProcessing file 189/444: audio_1290.wav\nProcessing file 190/444: audio_1162.wav\nProcessed 190 files. Taking a short break...\nProcessing file 191/444: audio_700.wav\nProcessing file 192/444: audio_1200.wav\nProcessing file 193/444: audio_147.wav\nProcessing file 194/444: audio_212.wav\nProcessing file 195/444: audio_168.wav\nProcessing file 196/444: audio_240.wav\nProcessing file 197/444: audio_695.wav\nProcessing file 198/444: audio_256.wav\nProcessing file 199/444: audio_443.wav\nProcessing file 200/444: audio_63.wav\nProcessed 200 files. Taking a short break...\nProcessing file 201/444: audio_721.wav\nProcessing file 202/444: audio_636.wav\nProcessing file 203/444: audio_870.wav\nProcessing file 204/444: audio_1335.wav\nProcessing file 205/444: audio_707.wav\nProcessing file 206/444: audio_581.wav\nProcessing file 207/444: audio_272.wav\nProcessing file 208/444: audio_1284.wav\nProcessing file 209/444: audio_1135.wav\nProcessing file 210/444: audio_1187.wav\nProcessed 210 files. Taking a short break...\nProcessing file 211/444: audio_480.wav\nProcessing file 212/444: audio_445.wav\nProcessing file 213/444: audio_447.wav\nProcessing file 214/444: audio_1191.wav\nProcessing file 215/444: audio_1266.wav\nProcessing file 216/444: audio_1307.wav\nProcessing file 217/444: audio_270.wav\nProcessing file 218/444: audio_1032.wav\nProcessing file 219/444: audio_931.wav\nProcessing file 220/444: audio_71.wav\nProcessed 220 files. Taking a short break...\nProcessing file 221/444: audio_482.wav\nProcessing file 222/444: audio_725.wav\nProcessing file 223/444: audio_301.wav\nProcessing file 224/444: audio_184.wav\nProcessing file 225/444: audio_387.wav\nProcessing file 226/444: audio_730.wav\nProcessing file 227/444: audio_980.wav\nProcessing file 228/444: audio_602.wav\nProcessing file 229/444: audio_874.wav\nProcessing file 230/444: audio_1148.wav\nProcessed 230 files. Taking a short break...\nProcessing file 231/444: audio_954.wav\nProcessing file 232/444: audio_185.wav\nProcessing file 233/444: audio_12.wav\nProcessing file 234/444: audio_241.wav\nProcessing file 235/444: audio_697.wav\nProcessing file 236/444: audio_548.wav\nProcessing file 237/444: audio_1128.wav\nProcessing file 238/444: audio_582.wav\nProcessing file 239/444: audio_925.wav\nProcessing file 240/444: audio_69.wav\nProcessed 240 files. Taking a short break...\nProcessing file 241/444: audio_896.wav\nProcessing file 242/444: audio_7.wav\nProcessing file 243/444: audio_611.wav\nProcessing file 244/444: audio_82.wav\nProcessing file 245/444: audio_591.wav\nProcessing file 246/444: audio_674.wav\nProcessing file 247/444: audio_753.wav\nProcessing file 248/444: audio_131.wav\nProcessing file 249/444: audio_1103.wav\nProcessing file 250/444: audio_961.wav\nProcessed 250 files. Taking a short break...\nProcessing file 251/444: audio_188.wav\nProcessing file 252/444: audio_926.wav\nProcessing file 253/444: audio_921.wav\nProcessing file 254/444: audio_955.wav\nProcessing file 255/444: audio_127.wav\nProcessing file 256/444: audio_327.wav\nProcessing file 257/444: audio_485.wav\nProcessing file 258/444: audio_705.wav\nProcessing file 259/444: audio_1147.wav\nProcessing file 260/444: audio_468.wav\nProcessed 260 files. Taking a short break...\nProcessing file 261/444: audio_477.wav\nProcessing file 262/444: audio_395.wav\nProcessing file 263/444: audio_1065.wav\nProcessing file 264/444: audio_254.wav\nProcessing file 265/444: audio_1017.wav\nProcessing file 266/444: audio_1196.wav\nProcessing file 267/444: audio_358.wav\nProcessing file 268/444: audio_716.wav\nProcessing file 269/444: audio_1236.wav\nProcessing file 270/444: audio_807.wav\nProcessed 270 files. Taking a short break...\nProcessing file 271/444: audio_490.wav\nProcessing file 272/444: audio_492.wav\nProcessing file 273/444: audio_469.wav\nProcessing file 274/444: audio_890.wav\nProcessing file 275/444: audio_600.wav\nProcessing file 276/444: audio_731.wav\nProcessing file 277/444: audio_339.wav\nProcessing file 278/444: audio_909.wav\nProcessing file 279/444: audio_658.wav\nProcessing file 280/444: audio_117.wav\nProcessed 280 files. Taking a short break...\nProcessing file 281/444: audio_1082.wav\nProcessing file 282/444: audio_291.wav\nProcessing file 283/444: audio_1066.wav\nProcessing file 284/444: audio_630.wav\nProcessing file 285/444: audio_404.wav\nProcessing file 286/444: audio_334.wav\nProcessing file 287/444: audio_33.wav\nProcessing file 288/444: audio_186.wav\nProcessing file 289/444: audio_693.wav\nProcessing file 290/444: audio_937.wav\nProcessed 290 files. Taking a short break...\nProcessing file 291/444: audio_424.wav\nProcessing file 292/444: audio_1262.wav\nProcessing file 293/444: audio_624.wav\nProcessing file 294/444: audio_620.wav\nProcessing file 295/444: audio_142.wav\nConverting stereo to mono for audio_142.wav\nProcessing file 296/444: audio_259.wav\nProcessing file 297/444: audio_503.wav\nProcessing file 298/444: audio_1125.wav\nProcessing file 299/444: audio_1332.wav\nProcessing file 300/444: audio_52.wav\nProcessed 300 files. Taking a short break...\nProcessing file 301/444: audio_558.wav\nProcessing file 302/444: audio_223.wav\nProcessing file 303/444: audio_194.wav\nProcessing file 304/444: audio_362.wav\nProcessing file 305/444: audio_1153.wav\nProcessing file 306/444: audio_200.wav\nProcessing file 307/444: audio_479.wav\nProcessing file 308/444: audio_455.wav\nProcessing file 309/444: audio_313.wav\nProcessing file 310/444: audio_15.wav\nProcessed 310 files. Taking a short break...\nProcessing file 311/444: audio_1100.wav\nProcessing file 312/444: audio_80.wav\nProcessing file 313/444: audio_887.wav\nProcessing file 314/444: audio_105.wav\nProcessing file 315/444: audio_483.wav\nProcessing file 316/444: audio_796.wav\nProcessing file 317/444: audio_2.wav\nProcessing file 318/444: audio_317.wav\nProcessing file 319/444: audio_963.wav\nProcessing file 320/444: audio_123.wav\nProcessed 320 files. Taking a short break...\nProcessing file 321/444: audio_1272.wav\nProcessing file 322/444: audio_315.wav\nProcessing file 323/444: audio_1202.wav\nProcessing file 324/444: audio_1008.wav\nProcessing file 325/444: audio_787.wav\nProcessing file 326/444: audio_1274.wav\nProcessing file 327/444: audio_265.wav\nConverting stereo to mono for audio_265.wav\nProcessing file 328/444: audio_1268.wav\nProcessing file 329/444: audio_526.wav\nProcessing file 330/444: audio_1285.wav\nProcessed 330 files. Taking a short break...\nProcessing file 331/444: audio_460.wav\nProcessing file 332/444: audio_696.wav\nProcessing file 333/444: audio_44.wav\nProcessing file 334/444: audio_478.wav\nProcessing file 335/444: audio_450.wav\nProcessing file 336/444: audio_1164.wav\nProcessing file 337/444: audio_245.wav\nProcessing file 338/444: audio_255.wav\nProcessing file 339/444: audio_513.wav\nProcessing file 340/444: audio_504.wav\nProcessed 340 files. Taking a short break...\nProcessing file 341/444: audio_590.wav\nProcessing file 342/444: audio_592.wav\nProcessing file 343/444: audio_389.wav\nProcessing file 344/444: audio_353.wav\nProcessing file 345/444: audio_250.wav\nProcessing file 346/444: audio_432.wav\nProcessing file 347/444: audio_583.wav\nProcessing file 348/444: audio_402.wav\nProcessing file 349/444: audio_312.wav\nProcessing file 350/444: audio_493.wav\nProcessed 350 files. Taking a short break...\nProcessing file 351/444: audio_516.wav\nProcessing file 352/444: audio_373.wav\nProcessing file 353/444: audio_119.wav\nProcessing file 354/444: audio_1175.wav\nProcessing file 355/444: audio_1160.wav\nProcessing file 356/444: audio_102.wav\nProcessing file 357/444: audio_140.wav\nProcessing file 358/444: audio_205.wav\nProcessing file 359/444: audio_414.wav\nProcessing file 360/444: audio_314.wav\nProcessed 360 files. Taking a short break...\nProcessing file 361/444: audio_374.wav\nProcessing file 362/444: audio_1177.wav\nProcessing file 363/444: audio_464.wav\nProcessing file 364/444: audio_518.wav\nProcessing file 365/444: audio_352.wav\nProcessing file 366/444: audio_396.wav\nProcessing file 367/444: audio_332.wav\nProcessing file 368/444: audio_495.wav\nProcessing file 369/444: audio_53.wav\nProcessing file 370/444: audio_463.wav\nProcessed 370 files. Taking a short break...\nProcessing file 371/444: audio_970.wav\nProcessing file 372/444: audio_120.wav\nProcessing file 373/444: audio_293.wav\nProcessing file 374/444: audio_688.wav\nProcessing file 375/444: audio_834.wav\nProcessing file 376/444: audio_440.wav\nProcessing file 377/444: audio_116.wav\nProcessing file 378/444: audio_359.wav\nProcessing file 379/444: audio_74.wav\nProcessing file 380/444: audio_154.wav\nProcessed 380 files. Taking a short break...\nProcessing file 381/444: audio_32.wav\nProcessing file 382/444: audio_413.wav\nProcessing file 383/444: audio_1075.wav\nProcessing file 384/444: audio_163.wav\nProcessing file 385/444: audio_1171.wav\nProcessing file 386/444: audio_745.wav\nProcessing file 387/444: audio_527.wav\nProcessing file 388/444: audio_202.wav\nProcessing file 389/444: audio_533.wav\nProcessing file 390/444: audio_226.wav\nProcessed 390 files. Taking a short break...\nProcessing file 391/444: audio_552.wav\nProcessing file 392/444: audio_978.wav\nConverting stereo to mono for audio_978.wav\nProcessing file 393/444: audio_994.wav\nProcessing file 394/444: audio_365.wav\nProcessing file 395/444: audio_1185.wav\nProcessing file 396/444: audio_826.wav\nProcessing file 397/444: audio_860.wav\nProcessing file 398/444: audio_23.wav\nProcessing file 399/444: audio_144.wav\nProcessing file 400/444: audio_586.wav\nProcessed 400 files. Taking a short break...\nProcessing file 401/444: audio_489.wav\nProcessing file 402/444: audio_694.wav\nProcessing file 403/444: audio_704.wav\nProcessing file 404/444: audio_783.wav\nProcessing file 405/444: audio_1059.wav\nProcessing file 406/444: audio_549.wav\nProcessing file 407/444: audio_627.wav\nProcessing file 408/444: audio_311.wav\nProcessing file 409/444: audio_118.wav\nProcessing file 410/444: audio_462.wav\nProcessed 410 files. Taking a short break...\nProcessing file 411/444: audio_419.wav\nProcessing file 412/444: audio_983.wav\nProcessing file 413/444: audio_1172.wav\nProcessing file 414/444: audio_436.wav\nProcessing file 415/444: audio_687.wav\nProcessing file 416/444: audio_514.wav\nProcessing file 417/444: audio_484.wav\nProcessing file 418/444: audio_1131.wav\nProcessing file 419/444: audio_55.wav\nProcessing file 420/444: audio_547.wav\nProcessed 420 files. Taking a short break...\nProcessing file 421/444: audio_652.wav\nProcessing file 422/444: audio_703.wav\nProcessing file 423/444: audio_9.wav\nProcessing file 424/444: audio_563.wav\nProcessing file 425/444: audio_1078.wav\nProcessing file 426/444: audio_758.wav\nProcessing file 427/444: audio_647.wav\nProcessing file 428/444: audio_867.wav\nProcessing file 429/444: audio_567.wav\nProcessing file 430/444: audio_471.wav\nProcessed 430 files. Taking a short break...\nProcessing file 431/444: audio_576.wav\nProcessing file 432/444: audio_210.wav\nProcessing file 433/444: audio_993.wav\nProcessing file 434/444: audio_390.wav\nProcessing file 435/444: audio_104.wav\nProcessing file 436/444: audio_366.wav\nProcessing file 437/444: audio_990.wav\nProcessing file 438/444: audio_1099.wav\nProcessing file 439/444: audio_609.wav\nProcessing file 440/444: audio_494.wav\nProcessed 440 files. Taking a short break...\nProcessing file 441/444: audio_363.wav\nProcessing file 442/444: audio_481.wav\nProcessing file 443/444: audio_989.wav\nProcessing file 444/444: audio_1163.wav\nTranscription complete! Saved to /kaggle/working/train_with_transcriptions.csv\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# # Print some examples\n# print(\"\\nExample transcriptions:\")\n# for i in range(min(5, len(df))):\n#     print(f\"File: {df.iloc[i]['file_name']}\")\n#     print(f\"Transcription: {df.iloc[i]['transcription']}\")\n#     print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.684833Z","iopub.execute_input":"2025-04-07T15:37:12.685082Z","iopub.status.idle":"2025-04-07T15:37:12.688446Z","shell.execute_reply.started":"2025-04-07T15:37:12.685033Z","shell.execute_reply":"2025-04-07T15:37:12.687801Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\n# Display the first 5 rows of the dataframe with transcriptions\ndf = pd.read_csv(\"/kaggle/working/train_with_transcriptions.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.689137Z","iopub.execute_input":"2025-04-07T15:37:12.689327Z","iopub.status.idle":"2025-04-07T15:37:12.725851Z","shell.execute_reply.started":"2025-04-07T15:37:12.689303Z","shell.execute_reply":"2025-04-07T15:37:12.725221Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"         filename  label                                      transcription\n0  audio_1261.wav    1.0  Спасибо. Cultivate my favorite hobbies cultiva...\n1   audio_942.wav    1.5  the playground looks like very clear and neat ...\n2  audio_1110.wav    1.5  my goal is to become an electrical employee an...\n3  audio_1024.wav    1.5  my favorite plate places is in on the place it...\n4   audio_538.wav    2.0  My favorite place is Uti and Kodai Canal. My e...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n      <th>transcription</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_1261.wav</td>\n      <td>1.0</td>\n      <td>Спасибо. Cultivate my favorite hobbies cultiva...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_942.wav</td>\n      <td>1.5</td>\n      <td>the playground looks like very clear and neat ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_1110.wav</td>\n      <td>1.5</td>\n      <td>my goal is to become an electrical employee an...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1024.wav</td>\n      <td>1.5</td>\n      <td>my favorite plate places is in on the place it...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_538.wav</td>\n      <td>2.0</td>\n      <td>My favorite place is Uti and Kodai Canal. My e...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Save the DataFrame to the working directory\noutput_file_path = \"/kaggle/working/transcribed_audio_data.csv\"\ndf.to_csv(output_file_path, index=False)\nprint(f\"Saved transcribed data to {output_file_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.726575Z","iopub.execute_input":"2025-04-07T15:37:12.726786Z","iopub.status.idle":"2025-04-07T15:37:12.738237Z","shell.execute_reply.started":"2025-04-07T15:37:12.726767Z","shell.execute_reply":"2025-04-07T15:37:12.737466Z"}},"outputs":[{"name":"stdout","text":"Saved transcribed data to /kaggle/working/transcribed_audio_data.csv\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.739146Z","iopub.execute_input":"2025-04-07T15:37:12.739489Z","iopub.status.idle":"2025-04-07T15:37:12.745001Z","shell.execute_reply.started":"2025-04-07T15:37:12.739444Z","shell.execute_reply":"2025-04-07T15:37:12.744169Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df_train['label'].min()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.745709Z","iopub.execute_input":"2025-04-07T15:37:12.745885Z","iopub.status.idle":"2025-04-07T15:37:12.759401Z","shell.execute_reply.started":"2025-04-07T15:37:12.745869Z","shell.execute_reply":"2025-04-07T15:37:12.758803Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"df_train['label'].max()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.760225Z","iopub.execute_input":"2025-04-07T15:37:12.760504Z","iopub.status.idle":"2025-04-07T15:37:12.775767Z","shell.execute_reply.started":"2025-04-07T15:37:12.760485Z","shell.execute_reply":"2025-04-07T15:37:12.775107Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"5.0"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# To check that any row has transcription column empty or NULL\ndf['transcription'].isnull().any() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.776615Z","iopub.execute_input":"2025-04-07T15:37:12.776850Z","iopub.status.idle":"2025-04-07T15:37:12.791135Z","shell.execute_reply.started":"2025-04-07T15:37:12.776822Z","shell.execute_reply":"2025-04-07T15:37:12.790274Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"df_train['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.791895Z","iopub.execute_input":"2025-04-07T15:37:12.792117Z","iopub.status.idle":"2025-04-07T15:37:12.818663Z","shell.execute_reply.started":"2025-04-07T15:37:12.792098Z","shell.execute_reply":"2025-04-07T15:37:12.817972Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"label\n5.0    110\n3.0     87\n2.0     70\n4.5     58\n4.0     52\n2.5     40\n3.5     23\n1.5      3\n1.0      1\nName: count, dtype: int64"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"**Now fine-tuning The DistillBert model for our dataset in regression problem & using PEFT technique(Lora) for training to maintain accuracy with less loss in performance and to utilize memory efficiently & Decrease the model training time.**","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import TrainingArguments, Trainer\nfrom datasets import Dataset\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom sklearn.metrics import mean_squared_error\n\n# Load the transcribed CSV file\ndf = pd.read_csv(\"/kaggle/working/transcribed_audio_data.csv\")\n\n# Drop the filename column (As we are having )\ndf_new = df.drop('filename', axis=1)\n\n# Display the dataframe structure\nprint(\"DataFrame structure after dropping filename column:\")\nprint(df_new.head())\n\n# Convert to dataset format for Hugging Face \ndf_new['label'] = df_new['label'].astype(float)  # Ensure labels are floats\n\n# Use entire dataset for training\ntrain_dataset = Dataset.from_pandas(df_new)\n\n# Load tokenizer and model\nmodel_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Define tokenization function\ndef tokenize_function(examples):\n    return tokenizer(examples[\"transcription\"], padding=\"max_length\", truncation=True, max_length=512)\n\n# Tokenize dataset\ntokenized_train = train_dataset.map(tokenize_function, batched=True)\n\n# Initialize DistilBERT model for regression\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=1,  # Single output for regression\n    problem_type=\"regression\"\n)\n\n# Configure LoRA\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    r=16,  # Rank\n    lora_alpha=32,\n    lora_dropout=0.1,\n    bias=\"none\",\n    target_modules=[\"q_lin\", \"v_lin\", \"k_lin\", \"out_lin\"]  # DistilBERT attention layers\n)\n\n# Apply LoRA to model\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()  # Show trainable vs total parameters\n\n# Fixed custom trainer class with MSE loss\nclass RegressionTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        labels = inputs.get(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fct = nn.MSELoss()\n        loss = loss_fct(logits.view(-1), labels.view(-1))\n        return (loss, outputs) if return_outputs else loss\n\n# Training arguments - utilizing both T4 GPUs\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/distilbert-audio-regression\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    num_train_epochs=100,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    fp16=True,\n    report_to=\"none\",\n    dataloader_num_workers=2,\n    # Add explicit logging settings\n    logging_dir=\"/kaggle/working/logs\",\n    logging_strategy=\"steps\",\n    logging_steps=10,  # Log every 10 steps\n    logging_first_step=True,  # Log the first step\n)\n\n# Initialize custom trainer with MSE loss\ntrainer = RegressionTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    tokenizer=tokenizer,\n)\n\n# Train model\ntrainer.train()\n\n# Save the model\ntrainer.save_model(\"/kaggle/working/distilbert-audio-regression-final\")\nprint(\"Model training complete and model saved!\")\n\n# Create a simple function to make predictions with the trained model\ndef predict_rating(text, model, tokenizer):\n    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n    with torch.no_grad():\n        outputs = model(**inputs)\n    return outputs.logits.cpu().numpy().squeeze()\n\n# Example prediction function (can be used after training)\nprint(\"Prediction function created. You can use predict_rating(text, model, tokenizer) to make predictions.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:37:12.819457Z","iopub.execute_input":"2025-04-07T15:37:12.819728Z","iopub.status.idle":"2025-04-07T15:54:01.603326Z","shell.execute_reply.started":"2025-04-07T15:37:12.819701Z","shell.execute_reply":"2025-04-07T15:54:01.602502Z"}},"outputs":[{"name":"stdout","text":"DataFrame structure after dropping filename column:\n   label                                      transcription\n0    1.0  Спасибо. Cultivate my favorite hobbies cultiva...\n1    1.5  the playground looks like very clear and neat ...\n2    1.5  my goal is to become an electrical employee an...\n3    1.5  my favorite plate places is in on the place it...\n4    2.0  My favorite place is Uti and Kodai Canal. My e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a39775e4d5984a948b5b887469537d2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a91ac38cb7ec40fca6ab4bb4a8768ee4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"285e3fd3df5744939975cfe178e34430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa8561dcd9b845f1a3badafe566b14a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"354de402382c46cfbea0980e0b75b540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50c402fdd40a476696d7f1a797b7a371"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n<ipython-input-30-7719c7e8e278>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `RegressionTrainer.__init__`. Use `processing_class` instead.\n  trainer = RegressionTrainer(\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 1,181,185 || all params: 68,135,426 || trainable%: 1.7336\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1400' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1400/1400 16:39, Epoch 100/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>14.388700</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>13.686300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>11.528700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>10.645800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>9.023100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>7.682900</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>6.038700</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>3.823400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.540200</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.475700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.244200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.051700</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.052200</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.019000</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.902900</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.858900</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.841500</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.722100</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.755900</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.749100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.790300</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.667200</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.682500</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.661700</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.737300</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.671700</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.652200</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.708500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.580400</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.644000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.584900</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.596800</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.612600</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.600600</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.583400</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.582100</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.580400</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.581200</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.516500</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.603800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.520500</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.536600</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.566400</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.580400</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.539500</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.511500</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.531800</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.510700</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.556100</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.522500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.518500</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.516200</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.526000</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.501800</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.503000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.551100</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.479200</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.513700</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.509100</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.433400</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.474600</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.488900</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.484700</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.501300</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.453800</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.482400</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.482400</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.498000</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.445500</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.484900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.473200</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.420300</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.437100</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.443100</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.471200</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.412900</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.520600</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.418200</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.372900</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.497000</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.431000</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.433500</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.415900</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.424100</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.403000</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.421600</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.388100</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.457700</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.442400</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.394000</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.413700</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.421800</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.436700</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.372100</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.427300</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.428700</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.411500</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.413600</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.394900</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.374000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.395200</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.374900</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.420600</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.389200</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.395200</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.419700</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.392100</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.379800</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.405100</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.403600</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.352000</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.428200</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.384900</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.354500</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.425000</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.346800</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.413400</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.402900</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.402600</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.354700</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.397100</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.414800</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.338700</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>0.385000</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.398900</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.363900</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.382800</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>0.386200</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.362300</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>0.389700</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.361100</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>0.384100</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.366100</td>\n    </tr>\n    <tr>\n      <td>1330</td>\n      <td>0.396300</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.359900</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.338200</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>0.411100</td>\n    </tr>\n    <tr>\n      <td>1370</td>\n      <td>0.318800</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.378500</td>\n    </tr>\n    <tr>\n      <td>1390</td>\n      <td>0.361400</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.371600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Model training complete and model saved!\nPrediction function created. You can use predict_rating(text, model, tokenizer) to make predictions.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport random\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom peft import PeftModel, PeftConfig\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/working/train_with_transcriptions.csv\")\n\n# Load the saved model and tokenizer\nmodel_path = \"/kaggle/working/distilbert-audio-regression-final\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\n# Load the base model and then apply the PEFT adapter\nbase_model_name = \"distilbert-base-uncased\"\nbase_model = AutoModelForSequenceClassification.from_pretrained(\n    base_model_name,\n    num_labels=1,\n    problem_type=\"regression\"\n)\nmodel = PeftModel.from_pretrained(base_model, model_path)\nmodel.eval()\n\n# Define prediction function\ndef predict_rating(text, model, tokenizer):\n    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n    with torch.no_grad():\n        outputs = model(**inputs)\n    return outputs.logits.cpu().numpy().squeeze()\n\n# Select random samples and make predictions\nrandom.seed(42)  # For reproducibility\nnum_samples = 5\nsample_indices = random.sample(range(len(df)), num_samples)\n\nprint(f\"\\nTesting model on {num_samples} random samples from training data:\\n\")\nprint(\"-\" * 80)\n\nfor idx in sample_indices:\n    sample = df.iloc[idx]\n    transcription = sample['transcription']\n    true_label = sample['label']\n    \n    # Get prediction\n    predicted_label = predict_rating(transcription, model, tokenizer)\n    \n    # Calculate error\n    error = abs(predicted_label - true_label)\n    \n    # Print results\n    print(f\"Sample {idx+1}:\")\n    print(f\"Transcription (truncated): {transcription[:100]}...\")\n    print(f\"True label: {true_label:.2f}\")\n    print(f\"Predicted label: {predicted_label:.2f}\")\n    print(f\"Absolute error: {error:.2f}\")\n    print(\"-\" * 80)\n\n# Calculate MSE for the random samples\nmse_samples = []\nfor idx in sample_indices:\n    sample = df.iloc[idx]\n    transcription = sample['transcription']\n    true_label = sample['label']\n    predicted_label = predict_rating(transcription, model, tokenizer)\n    mse_samples.append((predicted_label - true_label) ** 2)\n\nmse = sum(mse_samples) / len(mse_samples)\nprint(f\"Mean Squared Error (MSE) for these samples: {mse:.4f}\")\nprint(f\"Root Mean Squared Error (RMSE): {mse ** 0.5:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:54:01.605515Z","iopub.execute_input":"2025-04-07T15:54:01.605752Z","iopub.status.idle":"2025-04-07T15:54:04.587743Z","shell.execute_reply.started":"2025-04-07T15:54:01.605730Z","shell.execute_reply":"2025-04-07T15:54:04.586974Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nTesting model on 5 random samples from training data:\n\n--------------------------------------------------------------------------------\nSample 328:\nTranscription (truncated): The best day of my life is swimming in a cold spring. I'd invention the sensation of cool, clear wat...\nTrue label: 4.50\nPredicted label: 3.46\nAbsolute error: 1.04\n--------------------------------------------------------------------------------\nSample 58:\nTranscription (truncated): My topic is to describe about the best day in my life and the best day in my life is when I am study...\nTrue label: 2.50\nPredicted label: 2.37\nAbsolute error: 0.13\n--------------------------------------------------------------------------------\nSample 13:\nTranscription (truncated): Usually a playground looks very huge in a circular or like a bandage curved around. and running etc ...\nTrue label: 2.00\nPredicted label: 2.40\nAbsolute error: 0.40\n--------------------------------------------------------------------------------\nSample 380:\nTranscription (truncated): Oh Oh I'm not that you're not going to die. I'm a creep I can find the spots on your tail. I'm so gl...\nTrue label: 5.00\nPredicted label: 4.90\nAbsolute error: 0.10\n--------------------------------------------------------------------------------\nSample 141:\nTranscription (truncated): My favorite place is to visit Makkah and Medina. I am living currently in Anantapur. If I want to go...\nTrue label: 3.50\nPredicted label: 3.42\nAbsolute error: 0.08\n--------------------------------------------------------------------------------\nMean Squared Error (MSE) for these samples: 0.2542\nRoot Mean Squared Error (RMSE): 0.5042\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"**Now creating code to add transcription column in test csv file which we will pass to finetuned DistillBert model to predict label**","metadata":{}},{"cell_type":"code","source":"def main():\n    \"\"\"\n    Main function to run the transcription process.\n    \"\"\"\n    # Define paths\n    audio_folder = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test\"\n    csv_path = \"/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv\"\n    output_path = \"/kaggle/working/test_with_transcriptions.csv\"\n    \n    # Transcribe audio files\n    df = transcribe_audio_files(audio_folder, csv_path)\n    \n    # Save the updated dataframe\n    df.to_csv(output_path, index=False)\n    print(f\"Transcription complete! Saved to {output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:54:04.589117Z","iopub.execute_input":"2025-04-07T15:54:04.589451Z","iopub.status.idle":"2025-04-07T15:54:04.593090Z","shell.execute_reply.started":"2025-04-07T15:54:04.589427Z","shell.execute_reply":"2025-04-07T15:54:04.592417Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:54:04.593834Z","iopub.execute_input":"2025-04-07T15:54:04.594038Z","iopub.status.idle":"2025-04-07T15:59:58.194820Z","shell.execute_reply.started":"2025-04-07T15:54:04.594020Z","shell.execute_reply":"2025-04-07T15:59:58.193978Z"}},"outputs":[{"name":"stdout","text":"Loaded CSV with 195 entries\nUsing device: cuda:0\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\n/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting transcription process...\nProcessing file 1/195: audio_706.wav\nProcessing file 2/195: audio_800.wav\nProcessing file 3/195: audio_68.wav\nProcessing file 4/195: audio_1267.wav\nProcessing file 5/195: audio_683.wav\nProcessing file 6/195: audio_1242.wav\nProcessing file 7/195: audio_908.wav\nProcessing file 8/195: audio_888.wav\nProcessing file 9/195: audio_137.wav\nProcessing file 10/195: audio_770.wav\nProcessed 10 files. Taking a short break...\nProcessing file 11/195: audio_735.wav\nProcessing file 12/195: audio_1026.wav\nProcessing file 13/195: audio_1214.wav\nProcessing file 14/195: audio_1122.wav\nProcessing file 15/195: audio_1022.wav\nProcessing file 16/195: audio_726.wav\nProcessing file 17/195: audio_1205.wav\nProcessing file 18/195: audio_1116.wav\nProcessing file 19/195: audio_1240.wav\nProcessing file 20/195: audio_151.wav\nProcessed 20 files. Taking a short break...\nProcessing file 21/195: audio_437.wav\nProcessing file 22/195: audio_1217.wav\nProcessing file 23/195: audio_831.wav\nProcessing file 24/195: audio_1315.wav\nProcessing file 25/195: audio_1323.wav\nProcessing file 26/195: audio_1256.wav\nProcessing file 27/195: audio_1033.wav\nProcessing file 28/195: audio_858.wav\nProcessing file 29/195: audio_274.wav\nProcessing file 30/195: audio_196.wav\nProcessed 30 files. Taking a short break...\nProcessing file 31/195: audio_1193.wav\nProcessing file 32/195: audio_138.wav\nProcessing file 33/195: audio_644.wav\nProcessing file 34/195: audio_1012.wav\nProcessing file 35/195: audio_1101.wav\nProcessing file 36/195: audio_805.wav\nProcessing file 37/195: audio_709.wav\nProcessing file 38/195: audio_1293.wav\nProcessing file 39/195: audio_1123.wav\nProcessing file 40/195: audio_1048.wav\nProcessed 40 files. Taking a short break...\nProcessing file 41/195: audio_820.wav\nProcessing file 42/195: audio_767.wav\nProcessing file 43/195: audio_841.wav\nProcessing file 44/195: audio_1286.wav\nProcessing file 45/195: audio_665.wav\nProcessing file 46/195: audio_1311.wav\nProcessing file 47/195: audio_29.wav\nProcessing file 48/195: audio_1289.wav\nProcessing file 49/195: audio_177.wav\nProcessing file 50/195: audio_599.wav\nProcessed 50 files. Taking a short break...\nProcessing file 51/195: audio_920.wav\nProcessing file 52/195: audio_971.wav\nProcessing file 53/195: audio_1275.wav\nProcessing file 54/195: audio_1291.wav\nProcessing file 55/195: audio_320.wav\nProcessing file 56/195: audio_545.wav\nProcessing file 57/195: audio_287.wav\nProcessing file 58/195: audio_172.wav\nProcessing file 59/195: audio_322.wav\nProcessing file 60/195: audio_541.wav\nProcessed 60 files. Taking a short break...\nProcessing file 61/195: audio_148.wav\nProcessing file 62/195: audio_1317.wav\nProcessing file 63/195: audio_1243.wav\nProcessing file 64/195: audio_348.wav\nProcessing file 65/195: audio_662.wav\nProcessing file 66/195: audio_540.wav\nProcessing file 67/195: audio_733.wav\nProcessing file 68/195: audio_1297.wav\nProcessing file 69/195: audio_949.wav\nProcessing file 70/195: audio_1035.wav\nProcessed 70 files. Taking a short break...\nProcessing file 71/195: audio_882.wav\nProcessing file 72/195: audio_401.wav\nProcessing file 73/195: audio_113.wav\nProcessing file 74/195: audio_435.wav\nProcessing file 75/195: audio_719.wav\nProcessing file 76/195: audio_698.wav\nProcessing file 77/195: audio_959.wav\nProcessing file 78/195: audio_1166.wav\nProcessing file 79/195: audio_543.wav\nProcessing file 80/195: audio_89.wav\nProcessed 80 files. Taking a short break...\nProcessing file 81/195: audio_884.wav\nProcessing file 82/195: audio_19.wav\nProcessing file 83/195: audio_641.wav\nProcessing file 84/195: audio_1115.wav\nProcessing file 85/195: audio_811.wav\nProcessing file 86/195: audio_75.wav\nProcessing file 87/195: audio_1138.wav\nProcessing file 88/195: audio_66.wav\nProcessing file 89/195: audio_500.wav\nProcessing file 90/195: audio_922.wav\nProcessed 90 files. Taking a short break...\nProcessing file 91/195: audio_656.wav\nProcessing file 92/195: audio_218.wav\nProcessing file 93/195: audio_1278.wav\nProcessing file 94/195: audio_525.wav\nProcessing file 95/195: audio_290.wav\nProcessing file 96/195: audio_1195.wav\nProcessing file 97/195: audio_572.wav\nProcessing file 98/195: audio_1089.wav\nProcessing file 99/195: audio_488.wav\nProcessing file 100/195: audio_759.wav\nProcessed 100 files. Taking a short break...\nProcessing file 101/195: audio_103.wav\nProcessing file 102/195: audio_1280.wav\nProcessing file 103/195: audio_153.wav\nProcessing file 104/195: audio_300.wav\nProcessing file 105/195: audio_20.wav\nProcessing file 106/195: audio_10.wav\nProcessing file 107/195: audio_1292.wav\nProcessing file 108/195: audio_281.wav\nProcessing file 109/195: audio_261.wav\nProcessing file 110/195: audio_1081.wav\nProcessed 110 files. Taking a short break...\nProcessing file 111/195: audio_276.wav\nProcessing file 112/195: audio_159.wav\nConverting stereo to mono for audio_159.wav\nProcessing file 113/195: audio_1124.wav\nProcessing file 114/195: audio_690.wav\nProcessing file 115/195: audio_1061.wav\nProcessing file 116/195: audio_521.wav\nProcessing file 117/195: audio_263.wav\nProcessing file 118/195: audio_1068.wav\nProcessing file 119/195: audio_4.wav\nProcessing file 120/195: audio_676.wav\nProcessed 120 files. Taking a short break...\nProcessing file 121/195: audio_165.wav\nProcessing file 122/195: audio_282.wav\nProcessing file 123/195: audio_1179.wav\nProcessing file 124/195: audio_217.wav\nProcessing file 125/195: audio_388.wav\nProcessing file 126/195: audio_550.wav\nProcessing file 127/195: audio_499.wav\nProcessing file 128/195: audio_1190.wav\nProcessing file 129/195: audio_433.wav\nProcessing file 130/195: audio_885.wav\nProcessed 130 files. Taking a short break...\nProcessing file 131/195: audio_48.wav\nProcessing file 132/195: audio_308.wav\nProcessing file 133/195: audio_746.wav\nProcessing file 134/195: audio_1019.wav\nProcessing file 135/195: audio_487.wav\nProcessing file 136/195: audio_198.wav\nProcessing file 137/195: audio_958.wav\nProcessing file 138/195: audio_72.wav\nProcessing file 139/195: audio_1321.wav\nProcessing file 140/195: audio_1159.wav\nProcessed 140 files. Taking a short break...\nProcessing file 141/195: audio_428.wav\nProcessing file 142/195: audio_1058.wav\nProcessing file 143/195: audio_408.wav\nProcessing file 144/195: audio_857.wav\nProcessing file 145/195: audio_692.wav\nProcessing file 146/195: audio_633.wav\nProcessing file 147/195: audio_1173.wav\nProcessing file 148/195: audio_554.wav\nProcessing file 149/195: audio_180.wav\nProcessing file 150/195: audio_1013.wav\nProcessed 150 files. Taking a short break...\nProcessing file 151/195: audio_386.wav\nProcessing file 152/195: audio_519.wav\nProcessing file 153/195: audio_564.wav\nProcessing file 154/195: audio_1054.wav\nProcessing file 155/195: audio_556.wav\nProcessing file 156/195: audio_1183.wav\nProcessing file 157/195: audio_306.wav\nProcessing file 158/195: audio_713.wav\nProcessing file 159/195: audio_225.wav\nProcessing file 160/195: audio_1091.wav\nProcessed 160 files. Taking a short break...\nProcessing file 161/195: audio_107.wav\nProcessing file 162/195: audio_286.wav\nProcessing file 163/195: audio_546.wav\nProcessing file 164/195: audio_580.wav\nProcessing file 165/195: audio_235.wav\nProcessing file 166/195: audio_109.wav\nProcessing file 167/195: audio_932.wav\nProcessing file 168/195: audio_330.wav\nProcessing file 169/195: audio_569.wav\nProcessing file 170/195: audio_158.wav\nProcessed 170 files. Taking a short break...\nProcessing file 171/195: audio_321.wav\nProcessing file 172/195: audio_360.wav\nProcessing file 173/195: audio_391.wav\nProcessing file 174/195: audio_448.wav\nProcessing file 175/195: audio_1215.wav\nProcessing file 176/195: audio_422.wav\nProcessing file 177/195: audio_998.wav\nProcessing file 178/195: audio_702.wav\nProcessing file 179/195: audio_897.wav\nProcessing file 180/195: audio_394.wav\nProcessed 180 files. Taking a short break...\nProcessing file 181/195: audio_1169.wav\nProcessing file 182/195: audio_95.wav\nProcessing file 183/195: audio_604.wav\nProcessing file 184/195: audio_221.wav\nProcessing file 185/195: audio_34.wav\nProcessing file 186/195: audio_179.wav\nProcessing file 187/195: audio_21.wav\nProcessing file 188/195: audio_1176.wav\nProcessing file 189/195: audio_285.wav\nProcessing file 190/195: audio_1178.wav\nProcessed 190 files. Taking a short break...\nProcessing file 191/195: audio_135.wav\nProcessing file 192/195: audio_512.wav\nProcessing file 193/195: audio_529.wav\nProcessing file 194/195: audio_762.wav\nProcessing file 195/195: audio_379.wav\nTranscription complete! Saved to /kaggle/working/test_with_transcriptions.csv\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import pandas as pd\n# Display the first 5 rows of the dataframe with transcriptions\ndf_test = pd.read_csv(\"/kaggle/working/test_with_transcriptions.csv\")\ndf_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:59:58.195865Z","iopub.execute_input":"2025-04-07T15:59:58.196172Z","iopub.status.idle":"2025-04-07T15:59:58.208296Z","shell.execute_reply.started":"2025-04-07T15:59:58.196143Z","shell.execute_reply":"2025-04-07T15:59:58.207341Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"         filename                                      transcription\n0   audio_706.wav  I love you. I told you, you have to go to the ...\n1   audio_800.wav  My hobbies are playing cricket because I am a ...\n2    audio_68.wav  Yes, at this market you can find a lot of thin...\n3  audio_1267.wav  My goal is I become an interpreter, entreprene...\n4   audio_683.wav  Okay, in the cold market there is a lot of peo...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>transcription</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_706.wav</td>\n      <td>I love you. I told you, you have to go to the ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_800.wav</td>\n      <td>My hobbies are playing cricket because I am a ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_68.wav</td>\n      <td>Yes, at this market you can find a lot of thin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1267.wav</td>\n      <td>My goal is I become an interpreter, entreprene...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_683.wav</td>\n      <td>Okay, in the cold market there is a lot of peo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"Test_df = df_test.drop('filename', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:59:58.209340Z","iopub.execute_input":"2025-04-07T15:59:58.209668Z","iopub.status.idle":"2025-04-07T15:59:58.213915Z","shell.execute_reply.started":"2025-04-07T15:59:58.209633Z","shell.execute_reply":"2025-04-07T15:59:58.213045Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"Test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:59:58.215169Z","iopub.execute_input":"2025-04-07T15:59:58.215514Z","iopub.status.idle":"2025-04-07T15:59:58.232374Z","shell.execute_reply.started":"2025-04-07T15:59:58.215493Z","shell.execute_reply":"2025-04-07T15:59:58.231362Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                                       transcription\n0  I love you. I told you, you have to go to the ...\n1  My hobbies are playing cricket because I am a ...\n2  Yes, at this market you can find a lot of thin...\n3  My goal is I become an interpreter, entreprene...\n4  Okay, in the cold market there is a lot of peo...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transcription</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I love you. I told you, you have to go to the ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>My hobbies are playing cricket because I am a ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Yes, at this market you can find a lot of thin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My goal is I become an interpreter, entreprene...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Okay, in the cold market there is a lot of peo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"**Now we will load our finetuned model n pass our test_with_transcription.csv file**","metadata":{}},{"cell_type":"code","source":"# Load our fine-tuned model and tokenizer\nprint(\"Loading fine-tuned model...\")\nmodel_path = \"/kaggle/working/distilbert-audio-regression-final\"\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_path,\n    num_labels=1,\n    problem_type=\"regression\"\n)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\nmodel.eval()\n\n# Function to predict scores\ndef predict_rating(text, model, tokenizer, device):\n    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    # Get the prediction\n    prediction = outputs.logits.cpu().numpy().squeeze()\n    return prediction\n\n# Make predictions on test data\nprint(\"Making predictions...\")\npredictions = []\n\nfor text in df_test['transcription']:\n    score = predict_rating(text, model, tokenizer, device)\n    predictions.append(score)\n\n# Add predictions to the test dataframe\ndf_test['label'] = predictions\n\n# Create final submission DataFrame with only required columns\nsubmission_df = pd.DataFrame({\n    'filename': df_test['filename'],\n    'label': df_test['label']\n})\n\n# Save the submission file\nsubmission_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\nprint(\"Predictions completed\")\nprint(f\"Submission file created with {len(submission_df)} entries\")\nprint(\"First few predictions:\")\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:59:58.233274Z","iopub.execute_input":"2025-04-07T15:59:58.233519Z","iopub.status.idle":"2025-04-07T16:00:02.065655Z","shell.execute_reply.started":"2025-04-07T15:59:58.233500Z","shell.execute_reply":"2025-04-07T16:00:02.064769Z"}},"outputs":[{"name":"stdout","text":"Loading fine-tuned model...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Making predictions...\nPredictions completed\nSubmission file created with 195 entries\nFirst few predictions:\n         filename      label\n0   audio_706.wav  4.4122214\n1   audio_800.wav  2.8147244\n2    audio_68.wav  3.1968772\n3  audio_1267.wav  2.4250586\n4   audio_683.wav  2.8201332\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"df_submission = pd.read_csv(\"/kaggle/working/submission.csv\")\ndf_submission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:00:02.066616Z","iopub.execute_input":"2025-04-07T16:00:02.066906Z","iopub.status.idle":"2025-04-07T16:00:02.079121Z","shell.execute_reply.started":"2025-04-07T16:00:02.066880Z","shell.execute_reply":"2025-04-07T16:00:02.078148Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"         filename     label\n0   audio_706.wav  4.412221\n1   audio_800.wav  2.814724\n2    audio_68.wav  3.196877\n3  audio_1267.wav  2.425059\n4   audio_683.wav  2.820133","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_706.wav</td>\n      <td>4.412221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_800.wav</td>\n      <td>2.814724</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_68.wav</td>\n      <td>3.196877</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1267.wav</td>\n      <td>2.425059</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_683.wav</td>\n      <td>2.820133</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38}]}